{"ast":null,"code":"'use strict';\n\nvar _require = require('readable-stream'),\n    Transform = _require.Transform;\n\nvar util = require('util');\n\nvar defaults = require('defaults'); // some versions of the buffer browser lib don't support Buffer.from (such as the one included by the current version of express-browserify)\n\n\nvar bufferFrom = require('buffer-from');\n\nvar TARGET_SAMPLE_RATE = 16000;\n/**\n * Transforms Buffers or AudioBuffers into a binary stream of l16 (raw wav) audio, downsampling in the process.\n *\n * The watson speech-to-text service works on 16kHz and internally downsamples audio received at higher samplerates.\n * WebAudio is usually 44.1kHz or 48kHz, so downsampling here reduces bandwidth usage by ~2/3.\n *\n * Format event + stream can be combined with https://www.npmjs.com/package/wav to generate a wav file with a proper header\n *\n * Todo: support multi-channel audio (for use with <audio>/<video> elements) - will require interleaving audio channels\n *\n * @param {Object} options\n * @constructor\n */\n\nfunction WebAudioL16Stream(options) {\n  options = this.options = defaults(options, {\n    sourceSampleRate: 48000,\n    downsample: true\n  });\n  Transform.call(this, options);\n  this.bufferUnusedSamples = [];\n\n  if (options.objectMode || options.writableObjectMode) {\n    this._transform = this.handleFirstAudioBuffer;\n  } else {\n    this._transform = this.transformBuffer;\n    process.nextTick(this.emitFormat.bind(this));\n  }\n}\n\nutil.inherits(WebAudioL16Stream, Transform);\n\nWebAudioL16Stream.prototype.emitFormat = function emitFormat() {\n  this.emit('format', {\n    channels: 1,\n    bitDepth: 16,\n    sampleRate: this.options.downsample ? TARGET_SAMPLE_RATE : this.options.sourceSampleRate,\n    signed: true,\n    float: false\n  });\n};\n/**\n * Downsamples WebAudio to 16 kHz.\n *\n * Browsers can downsample WebAudio natively with OfflineAudioContext's but it was designed for non-streaming use and\n * requires a new context for each AudioBuffer. Firefox can handle this, but chrome (v47) crashes after a few minutes.\n * So, we'll do it in JS for now.\n *\n * This really belongs in it's own stream, but there's no way to create new AudioBuffer instances from JS, so its\n * fairly coupled to the wav conversion code.\n *\n * @param  {AudioBuffer} bufferNewSamples Microphone/MediaElement audio chunk\n * @return {Float32Array} 'audio/l16' chunk\n */\n\n\nWebAudioL16Stream.prototype.downsample = function downsample(bufferNewSamples) {\n  var buffer = null;\n  var newSamples = bufferNewSamples.length;\n  var unusedSamples = this.bufferUnusedSamples.length;\n  var i;\n  var offset;\n\n  if (unusedSamples > 0) {\n    buffer = new Float32Array(unusedSamples + newSamples);\n\n    for (i = 0; i < unusedSamples; ++i) {\n      buffer[i] = this.bufferUnusedSamples[i];\n    }\n\n    for (i = 0; i < newSamples; ++i) {\n      buffer[unusedSamples + i] = bufferNewSamples[i];\n    }\n  } else {\n    buffer = bufferNewSamples;\n  } // Downsampling and low-pass filter:\n  // Input audio is typically 44.1kHz or 48kHz, this downsamples it to 16kHz.\n  // It uses a FIR (finite impulse response) Filter to remove (or, at least attinuate)\n  // audio frequencies > ~8kHz because sampled audio cannot accurately represent\n  // frequiencies greater than half of the sample rate.\n  // (Human voice tops out at < 4kHz, so nothing important is lost for transcription.)\n  // See http://dsp.stackexchange.com/a/37475/26392 for a good explination of this code.\n\n\n  var filter = [-0.037935, -0.00089024, 0.040173, 0.019989, 0.0047792, -0.058675, -0.056487, -0.0040653, 0.14527, 0.26927, 0.33913, 0.26927, 0.14527, -0.0040653, -0.056487, -0.058675, 0.0047792, 0.019989, 0.040173, -0.00089024, -0.037935];\n  var samplingRateRatio = this.options.sourceSampleRate / TARGET_SAMPLE_RATE;\n  var nOutputSamples = Math.floor((buffer.length - filter.length) / samplingRateRatio) + 1;\n  var outputBuffer = new Float32Array(nOutputSamples);\n\n  for (i = 0; i < outputBuffer.length; i++) {\n    offset = Math.round(samplingRateRatio * i);\n    var sample = 0;\n\n    for (var j = 0; j < filter.length; ++j) {\n      sample += buffer[offset + j] * filter[j];\n    }\n\n    outputBuffer[i] = sample;\n  }\n\n  var indexSampleAfterLastUsed = Math.round(samplingRateRatio * i);\n  var remaining = buffer.length - indexSampleAfterLastUsed;\n\n  if (remaining > 0) {\n    this.bufferUnusedSamples = new Float32Array(remaining);\n\n    for (i = 0; i < remaining; ++i) {\n      this.bufferUnusedSamples[i] = buffer[indexSampleAfterLastUsed + i];\n    }\n  } else {\n    this.bufferUnusedSamples = new Float32Array(0);\n  }\n\n  return outputBuffer;\n};\n/**\n * Accepts a Float32Array of audio data and converts it to a Buffer of l16 audio data (raw wav)\n *\n * Explanation for the math: The raw values captured from the Web Audio API are\n * in 32-bit Floating Point, between -1 and 1 (per the specification).\n * The values for 16-bit PCM range between -32768 and +32767 (16-bit signed integer).\n * Filter & combine samples to reduce frequency, then multiply to by 0x7FFF (32767) to convert.\n * Store in little endian.\n *\n * @param {Float32Array} input\n * @return {Buffer}\n */\n\n\nWebAudioL16Stream.prototype.floatTo16BitPCM = function (input) {\n  var output = new DataView(new ArrayBuffer(input.length * 2)); // length is in bytes (8-bit), so *2 to get 16-bit length\n\n  for (var i = 0; i < input.length; i++) {\n    var multiplier = input[i] < 0 ? 0x8000 : 0x7fff; // 16-bit signed range is -32768 to 32767\n\n    output.setInt16(i * 2, input[i] * multiplier | 0, true); // index, value (\"| 0\" = convert to 32-bit int, round towards 0), littleEndian.\n  }\n\n  return bufferFrom(output.buffer);\n};\n/**\n * Does some one-time setup to grab sampleRate and emit format, then sets _transform to the actual audio buffer handler and calls it.\n * @param {AudioBuffer} audioBuffer\n * @param {String} encoding\n * @param {Function} next\n */\n\n\nWebAudioL16Stream.prototype.handleFirstAudioBuffer = function handleFirstAudioBuffer(audioBuffer, encoding, next) {\n  this.options.sourceSampleRate = audioBuffer.sampleRate;\n  this.emitFormat();\n  this._transform = this.transformAudioBuffer;\n\n  this._transform(audioBuffer, encoding, next);\n};\n/**\n * Accepts an AudioBuffer (for objectMode), then downsamples to 16000 and converts to a 16-bit pcm\n *\n * @param {AudioBuffer} audioBuffer\n * @param {String} encoding\n * @param {Function} next\n */\n\n\nWebAudioL16Stream.prototype.transformAudioBuffer = function (audioBuffer, encoding, next) {\n  var source = audioBuffer.getChannelData(0);\n\n  if (this.options.downsample) {\n    source = this.downsample(source);\n  }\n\n  this.push(this.floatTo16BitPCM(source));\n  next();\n};\n/**\n * Accepts a Buffer (for binary mode), then downsamples to 16000 and converts to a 16-bit pcm\n *\n * @param {Buffer} nodebuffer\n * @param {String} encoding\n * @param {Function} next\n */\n\n\nWebAudioL16Stream.prototype.transformBuffer = function (nodebuffer, encoding, next) {\n  var source = new Float32Array(nodebuffer.buffer);\n\n  if (this.options.downsample) {\n    source = this.downsample(source);\n  }\n\n  this.push(this.floatTo16BitPCM(source));\n  next();\n}; // new Float32Array(nodebuffer.buffer)\n\n\nmodule.exports = WebAudioL16Stream;","map":null,"metadata":{},"sourceType":"script"}