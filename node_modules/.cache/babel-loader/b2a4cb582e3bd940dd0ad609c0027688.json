{"ast":null,"code":"/**\n * Copyright 2014 IBM Corp. All Rights Reserved.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n'use strict';\n\nvar _require = require('readable-stream'),\n    Duplex = _require.Duplex;\n\nvar util = require('util');\n\nvar pick = require('object.pick');\n\nvar W3CWebSocket = require('websocket').w3cwebsocket;\n\nvar contentType = require('./content-type');\n\nvar qs = require('../util/querystring.js');\n\nvar OPENING_MESSAGE_PARAMS_ALLOWED = ['action', 'customization_weight', 'processing_metrics', 'processing_metrics_interval', 'audio_metrics', 'inactivity_timeout', 'timestamps', 'word_confidence', 'content-type', 'interim_results', 'keywords', 'keywords_threshold', 'max_alternatives', 'word_alternatives_threshold', 'profanity_filter', 'smart_formatting', 'speaker_labels', 'grammar_name', 'redaction'];\nvar QUERY_PARAMS_ALLOWED = ['model', 'X-Watson-Learning-Opt-Out', 'watson-token', 'language_customization_id', 'customization_id', 'acoustic_customization_id', 'access_token', 'base_model_version', 'x-watson-metadata'];\n/**\n * pipe()-able Node.js Duplex stream - accepts binary audio and emits text/objects in it's `data` events.\n *\n * Uses WebSockets under the hood. For audio with no recognizable speech, no `data` events are emitted.\n *\n * By default, only finalized text is emitted in the data events, however when `objectMode`/`readableObjectMode` and `interim_results` are enabled, both interim and final results objects are emitted.\n * WriteableElementStream uses this, for example, to live-update the DOM with word-by-word transcriptions.\n *\n * Note that the WebSocket connection is not established until the first chunk of data is recieved. This allows for auto-detection of content type (for wav/flac/opus audio).\n *\n * @param {Object} options\n * @param {String} [options.model='en-US_BroadbandModel'] - voice model to use. Microphone streaming only supports broadband models.\n * @param {String} [options.url='wss://stream.watsonplatform.net/speech-to-text/api'] base URL for service\n * @param {String} [options.token] - Auth token for CF services\n * @param {String} options.access_token - IAM Access Token for RC services\n * @param {Object} [options.headers] - Only works in Node.js, not in browsers. Allows for custom headers to be set, including an Authorization header (preventing the need for auth tokens)\n * @param {String} [options.content-type='audio/wav'] - content type of audio; can be automatically determined from file header in most cases. only wav, flac, ogg/opus, and webm are supported\n * @param {Boolean} [options.interim_results=false] - Send back non-final previews of each \"sentence\" as it is being processed. These results are ignored in text mode.\n * @param {Boolean} [options.word_confidence=false] - include confidence scores with results.\n * @param {Boolean} [options.timestamps=false] - include timestamps with results.\n * @param {Number} [options.max_alternatives=1] - maximum number of alternative transcriptions to include.\n * @param {Array<String>} [options.keywords] - a list of keywords to search for in the audio\n * @param {Number} [options.keywords_threshold] - Number between 0 and 1 representing the minimum confidence before including a keyword in the results. Required when options.keywords is set\n * @param {Number} [options.word_alternatives_threshold] - Number between 0 and 1 representing the minimum confidence before including an alternative word in the results. Must be set to enable word alternatives,\n * @param {Boolean} [options.profanity_filter=false] - set to true to filter out profanity and replace the words with *'s\n * @param {Number} [options.inactivity_timeout=30] - how many seconds of silence before automatically closing the stream. use -1 for infinity\n * @param {Boolean} [options.readableObjectMode=false] - emit `result` objects instead of string Buffers for the `data` events. Does not affect input (which must be binary)\n * @param {Boolean} [options.objectMode=false] - alias for options.readableObjectMode\n * @param {Number} [options.X-Watson-Learning-Opt-Out=false] - set to true to opt-out of allowing Watson to use this request to improve it's services\n * @param {Boolean} [options.smart_formatting=false] - formats numeric values such as dates, times, currency, etc.\n * @param {String} [options.customization_id] - Customization ID\n * @param {String} [options.acoustic_customization_id] - Acoustic customization ID\n * @param {String} [options.grammar_name] - Name of grammar\n *\n * @constructor\n */\n\nfunction RecognizeStream(options) {\n  // this stream only supports objectMode on the output side.\n  // It must receive binary data input.\n  if (options.objectMode) {\n    options.readableObjectMode = true;\n    delete options.objectMode;\n  }\n\n  Duplex.call(this, options);\n  this.options = options;\n  this.listening = false;\n  this.initialized = false;\n  this.finished = false;\n  this.on('newListener', function (event) {\n    if (!options.silent) {\n      if (event === 'results' || event === 'result' || event === 'speaker_labels') {\n        // eslint-disable-next-line no-console\n        console.log(new Error('Watson Speech to Text RecognizeStream: the ' + event + ' event was deprecated. ' + \"Please set {objectMode: true} and listen for the 'data' event instead. \" + 'Pass {silent: true} to disable this message.'));\n      } else if (event === 'connection-close') {\n        // eslint-disable-next-line no-console\n        console.log(new Error('Watson Speech to Text RecognizeStream: the ' + event + ' event was deprecated. ' + \"Please listen for the 'close' event instead. \" + 'Pass {silent: true} to disable this message.'));\n      } else if (event === 'connect') {\n        // eslint-disable-next-line no-console\n        console.log(new Error('Watson Speech to Text RecognizeStream: the ' + event + ' event was deprecated. ' + \"Please listen for the 'open' event instead. \" + 'Pass {silent: true} to disable this message.'));\n      }\n    }\n  });\n}\n\nutil.inherits(RecognizeStream, Duplex);\nRecognizeStream.WEBSOCKET_CONNECTION_ERROR = 'WebSocket connection error';\n\nRecognizeStream.prototype.initialize = function () {\n  var options = this.options;\n\n  if (options.token && !options['watson-token']) {\n    options['watson-token'] = options.token;\n  }\n\n  if (options.content_type && !options['content-type']) {\n    options['content-type'] = options.content_type;\n  }\n\n  if (options['X-WDC-PL-OPT-OUT'] && !options['X-Watson-Learning-Opt-Out']) {\n    options['X-Watson-Learning-Opt-Out'] = options['X-WDC-PL-OPT-OUT'];\n  } // compatibility code for the deprecated param, customization_id\n\n\n  if (options.customization_id && !options.language_customization_id) {\n    options.language_customization_id = options.customization_id;\n    delete options.customization_id;\n  }\n\n  var queryParams = util._extend('language_customization_id' in options ? pick(options, QUERY_PARAMS_ALLOWED) : {\n    model: 'en-US_BroadbandModel'\n  }, pick(options, QUERY_PARAMS_ALLOWED));\n\n  var queryString = qs.stringify(queryParams);\n  var url = (options.url || 'wss://stream.watsonplatform.net/speech-to-text/api').replace(/^http/, 'ws') + '/v1/recognize?' + queryString;\n  var openingMessage = pick(options, OPENING_MESSAGE_PARAMS_ALLOWED);\n  openingMessage.action = 'start';\n  var self = this; // node params: requestUrl, protocols, origin, headers, extraRequestOptions\n  // browser params: requestUrl, protocols (all others ignored)\n\n  var socket = this.socket = new W3CWebSocket(url, null, null, options.headers, null); // when the input stops, let the service know that we're done\n\n  self.on('finish', self.finish.bind(self));\n  /**\n   * This can happen if the credentials are invalid - in that case, the response from DataPower doesn't include the\n   * necessary CORS headers, so JS can't even read it :(\n   *\n   * @param {Event} event - event object with essentially no useful information\n   */\n\n  socket.onerror = function (event) {\n    self.listening = false;\n    var err = new Error('WebSocket connection error');\n    err.name = RecognizeStream.WEBSOCKET_CONNECTION_ERROR;\n    err.event = event;\n    self.emit('error', err);\n    self.push(null);\n  };\n\n  this.socket.onopen = function () {\n    self.sendJSON(openingMessage);\n    /**\n     * emitted once the WebSocket connection has been established\n     * @event RecognizeStream#open\n     */\n\n    self.emit('open');\n  };\n\n  this.socket.onclose = function (e) {\n    // if (self.listening) {\n    self.listening = false;\n    self.push(null); // }\n\n    /**\n     * @event RecognizeStream#close\n     * @param {Number} reasonCode\n     * @param {String} description\n     */\n\n    self.emit('close', e.code, e.reason);\n  };\n  /**\n   * @event RecognizeStream#error\n   * @param {String} msg custom error message\n   * @param {*} [frame] unprocessed frame (should have a .data property with either string or binary data)\n   * @param {Error} [err]\n   */\n\n\n  function emitError(msg, frame, err) {\n    if (err) {\n      err.message = msg + ' ' + err.message;\n    } else {\n      err = new Error(msg);\n    }\n\n    err.raw = frame;\n    self.emit('error', err);\n  }\n\n  socket.onmessage = function (frame) {\n    if (typeof frame.data !== 'string') {\n      return emitError('Unexpected binary data received from server', frame);\n    }\n\n    var data;\n\n    try {\n      data = JSON.parse(frame.data);\n    } catch (jsonEx) {\n      return emitError('Invalid JSON received from service:', frame, jsonEx);\n    }\n    /**\n     * Emit any messages received over the wire, mainly used for debugging.\n     *\n     * @event RecognizeStream#message\n     * @param {Object} message - frame object with a data attribute that's either a string or a Buffer/TypedArray\n     * @param {Object} [data] - parsed JSON object (if possible);\n     */\n\n\n    self.emit('message', frame, data);\n\n    if (data.error) {\n      emitError(data.error, frame);\n    } else if (data.state === 'listening') {\n      // this is emitted both when the server is ready for audio, and after we send the close message to indicate that it's done processing\n      if (self.listening) {\n        self.listening = false;\n        socket.close();\n      } else {\n        self.listening = true;\n        /**\n         * Emitted when the Watson Service indicates readiness to transcribe audio. Any audio sent before this point will be buffered until now.\n         * @event RecognizeStream#listening\n         */\n\n        self.emit('listening');\n      }\n    } else {\n      if (options.readableObjectMode) {\n        /**\n         * Object with interim or final results, possibly including confidence scores, alternatives, and word timing.\n         * @event RecognizeStream#data\n         * @param {Object} data\n         */\n        self.push(data);\n      } else if (Array.isArray(data.results)) {\n        data.results.forEach(function (result) {\n          if (result.final && result.alternatives) {\n            /**\n             * Finalized text\n             * @event RecognizeStream#data\n             * @param {String} transcript\n             */\n            self.push(result.alternatives[0].transcript, 'utf8');\n          }\n        });\n      }\n    }\n  };\n\n  this.initialized = true;\n};\n\nRecognizeStream.prototype.sendJSON = function sendJSON(msg) {\n  /**\n   * Emits any JSON object sent to the service from the client. Mainly used for debugging.\n   * @event RecognizeStream#send-json\n   * @param {Object} msg\n   */\n  this.emit('send-json', msg);\n  return this.socket.send(JSON.stringify(msg));\n};\n\nRecognizeStream.prototype.sendData = function sendData(data) {\n  /**\n   * Emits any Binary object sent to the service from the client. Mainly used for debugging.\n   * @event RecognizeStream#send-data\n   * @param {Object} msg\n   */\n  this.emit('send-data', data);\n  return this.socket.send(data);\n};\n\nRecognizeStream.prototype._read = function ()\n/* size*/\n{// there's no easy way to control reads from the underlying library\n  // so, the best we can do here is a no-op\n};\n\nRecognizeStream.ERROR_UNRECOGNIZED_FORMAT = 'UNRECOGNIZED_FORMAT';\n\nRecognizeStream.prototype._write = function (chunk, encoding, callback) {\n  var self = this;\n\n  if (self.finished) {\n    // can't send any more data after the stop message (although this shouldn't happen normally...)\n    return;\n  }\n\n  if (!this.initialized) {\n    if (!this.options['content-type']) {\n      var ct = RecognizeStream.getContentType(chunk);\n\n      if (ct) {\n        this.options['content-type'] = ct;\n      } else {\n        var err = new Error('Unable to determine content-type from file header, please specify manually.');\n        err.name = RecognizeStream.ERROR_UNRECOGNIZED_FORMAT;\n        this.emit('error', err);\n        this.push(null);\n        return;\n      }\n    }\n\n    this.initialize();\n    this.once('open', function () {\n      self.sendData(chunk);\n      self.afterSend(callback);\n    });\n  } else {\n    self.sendData(chunk);\n    this.afterSend(callback);\n  }\n};\n/**\n * Flow control - don't ask for more data until we've finished what we have\n *\n * Notes:\n *\n * This limits upload speed to 100 * options.highWaterMark / second.\n *\n * The default highWaterMark is 16kB, so the default max upload speed is ~1.6MB/s.\n *\n * Microphone input provides audio at a (downsampled) rate of:\n *   16000 samples/s * 16-bits * 1 channel = 32kB/s\n * (note the bits to Bytes conversion there)\n *\n * @private\n * @param {Function} next\n */\n\n\nRecognizeStream.prototype.afterSend = function afterSend(next) {\n  if (this.socket.bufferedAmount <= (this._writableState.highWaterMark || 0)) {\n    process.nextTick(next);\n  } else {\n    setTimeout(this.afterSend.bind(this, next), 10);\n  }\n};\n/**\n * Prevents any more audio from being sent over the WebSocket and gracefully closes the connection.\n * Additional data may still be emitted up until the `end` event is triggered.\n */\n\n\nRecognizeStream.prototype.stop = function () {\n  /**\n   * Event emitted when the stop method is called. Mainly for synchronising with file reading and playback.\n   * @event RecognizeStream#stop\n   */\n  this.emit('stop');\n  this.finish();\n};\n\nRecognizeStream.prototype.finish = function finish() {\n  // this is called both when the source stream finishes, and when .stop() is fired, but we only want to send the stop message once.\n  if (this.finished) {\n    return;\n  }\n\n  this.finished = true;\n  var self = this;\n  var closingMessage = {\n    action: 'stop'\n  };\n\n  if (self.socket && self.socket.readyState === self.socket.OPEN) {\n    self.sendJSON(closingMessage);\n  } else {\n    this.once('open', function () {\n      self.sendJSON(closingMessage);\n    });\n  }\n};\n\nRecognizeStream.prototype.promise = require('./to-promise');\n\nRecognizeStream.getContentType = function (buffer) {\n  // the substr really shouldn't be necessary, but there's a bug somewhere that can cause buffer.slice(0,4) to return\n  // the entire contents of the buffer, so it's a failsafe to catch that\n  return contentType.fromHeader(buffer);\n};\n\nmodule.exports = RecognizeStream;","map":null,"metadata":{},"sourceType":"script"}